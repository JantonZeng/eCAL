{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from tornado import gen, httpclient, ioloop\n",
    "from requests import get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen.coroutine\n",
    "def get_url(url):\n",
    "    wait_time = random.randint(1,4)\n",
    "    yield gen.sleep(wait_time)\n",
    "    print('URL {} took {}s to get!'.format(url, wait_time))\n",
    "    raise gen.Return((url, wait_time))\n",
    "\n",
    "@gen.coroutine\n",
    "def outer_coroutine():\n",
    "    before = time.time()\n",
    "    coroutines = [get_url(url) for url in ['URL1', 'URL2', 'URL3']]\n",
    "    result = yield coroutines\n",
    "    after = time.time()\n",
    "    print(result)\n",
    "    print('total time: {} seconds'.format(after-before))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    loop = ioloop.IOLoop()\n",
    "    loop.run_sync(outer_coroutine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SynSpider(object):\n",
    "    def __init__(self, urls):\n",
    "        self.urls = urls\n",
    "        \n",
    "    def fetch_url(self, url):\n",
    "        r = get(url)\n",
    "        return r.content\n",
    "    def handle_page(self, html):\n",
    "#         pass\n",
    "        print html\n",
    "    \n",
    "    def run(self):\n",
    "        for url in urls:\n",
    "            html = self.fetch_url(url)\n",
    "            self.handle_page(html)\n",
    "\n",
    "class AsyncSpider(object):\n",
    "    def __init__(sefl, urls):\n",
    "        sefl.urls = urls\n",
    "    \n",
    "    @gen.coroutine\n",
    "    def fetch_url(sefl, url):\n",
    "        try:\n",
    "            response = yield httpclient.AsyncHTTPClient().fetch(url)\n",
    "        except:\n",
    "            print('fetch failed')\n",
    "            raise gen.Return('')\n",
    "            \n",
    "    def handle_page(sefl, html):\n",
    "#         pass\n",
    "        print html\n",
    "    \n",
    "    @gen.coroutine\n",
    "    def _run(self):\n",
    "        for url in self.urls:\n",
    "            html = yield self.fetch_url(url)\n",
    "            self.handle_page(html)\n",
    "    \n",
    "    def run(self):\n",
    "        io_loop = ioloop.IOLoop()\n",
    "        io_loop.run_sync(self._run)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    num = 1000\n",
    "    urls = ['http://www.baidu.com']*num\n",
    "    \n",
    "    _st1 = time.time()\n",
    "    s = AsyncSpider(urls)\n",
    "    s.run()\n",
    "    _end1 = time.time()\n",
    "    \n",
    "    _st2 = time.time()\n",
    "    s1 = SynSpider(urls)\n",
    "    s1.run()\n",
    "    _end2 = time.time()\n",
    "    \n",
    "    print _end1 - _st1\n",
    "    print _end2 - _st2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
